# Monet风格转换 CycleGAN

基于CycleGAN的照片与莫奈画作风格转换项目。该项目实现了双向风格转换：
- 将真实照片转换为莫奈画作风格
- 将莫奈画作风格转换为真实照片风格

## 项目特点

- 双向风格转换
- 改进的FID评估方法
- 优化的训练策略
- 使用Wandb进行实验跟踪
- 混合精度训练
- 自动学习率调整

## 环境要求

```bash
torch>=1.7.0
torchvision>=0.8.0
wandb
numpy
pillow
tqdm
scipy
pytorch-fid
```

## 项目结构

```
.
├── data/
│   ├── trainA/    # 训练集照片
│   ├── trainB/    # 训练集莫奈画作
│   ├── testA/     # 测试集照片
│   └── testB/     # 测试集莫奈画作
├── models/
│   ├── generator.py       # 生成器模型
│   └── discriminator.py   # 判别器模型
├── utils/
│   ├── dataset.py        # 数据集加载
│   └── fid_score.py      # FID分数计算
├── train.py              # 训练脚本
├── recalculate_fid.py    # FID重新计算脚本
└── README.md
```

## 技术细节

### 模型架构

#### 生成器 (Generator)
- 基于ResNet架构
- 9个残差块用于特征提取和转换
- 使用实例归一化避免风格信息损失
- 反射填充保持边缘一致性
- Tanh激活函数确保输出范围在[-1,1]

#### 判别器 (Discriminator)
- PatchGAN结构，关注局部特征
- 实例归一化
- LeakyReLU激活函数（斜率0.2）
- 70x70感受野

### 损失函数

1. GAN Loss
   - 使用MSE损失
   - 带标签平滑的真实标签和虚假标签
   - 用于提升生成图像的真实性

2. Cycle Loss (循环一致性损失)
   - L1损失
   - 权重：20.0
   - 确保图像转换的可逆性
   - 保持内容的一致性

3. Identity Loss (身份损失)
   - L1损失
   - 权重：10.0
   - 帮助保持颜色和整体构图
   - 防止不必要的风格转换

### 评估指标

#### FID分数 (Fréchet Inception Distance)
- 使用预训练的Inception-v3模型提取特征
- 计算真实图像和生成图像特征分布的距离
- 分别评估两个域的转换质量：
  - 照片域FID：测试集真实照片(774张)vs生成照片
  - 莫奈域FID：测试集莫奈画作(131张)vs生成莫奈画作
- 每10个epoch计算一次
- 值越低表示生成质量越好
- 使用独立的测试集评估，确保评估的客观性

## 训练策略

### 基础配置
```python
config = {
    'epochs': 200,
    'batch_size': 8,
    'lr': 0.0001,
    'b1': 0.5,
    'b2': 0.999,
    'lambda_cycle': 15.0,
    'lambda_identity': 7.5,
    'gradient_accumulation_steps': 4
}
```

### 优化技巧
1. 学习率调度：
   - 预热阶段（5个epoch）
   - 恒定学习率阶段
   - 线性衰减（从100epoch开始）

2. 训练稳定性：
   - 梯度累积（每4步更新一次）
   - 混合精度训练（降低显存使用）
   - 较大的batch size（8）提高稳定性

3. 检查点保存：
   - 每5个epoch保存一次
   - 保存完整的训练状态
   - 支持断点续训

## 实验过程与结果

本节整合了**本项目自定义训练**与**CycleGAN源码训练**(125轮)的结果，用于对比和分析。

### 1. 本项目的训练过程与结果

#### 1.1 训练曲线展示
<div align="center">
  <div class="training-visualization">
    <img src="assets/200epoch_1.jpg" alt="训练曲线图1" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>📈 前 200epoch 学习率、FID分数和生成器损失变化曲线</i></p>
    <br>
    <img src="assets/200epoch_2.jpg" alt="训练曲线图2" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>📊 前 200epoch 判别器损失、循环一致性损失和身份损失变化曲线</i></p>
  </div>
</div>

#### 1.2 测试集FID评估结果
<div align="center">
  <img src="assets/test_fid_scores.png" alt="测试集FID分数变化" width="80%">
  <p><i>📊 测试集FID分数变化趋势</i></p>
  <br>
  <table>
    <tr>
      <th>指标</th>
      <th>数值</th>
    </tr>
    <tr>
      <td>照片域FID</td>
      <td>121.49</td>
    </tr>
    <tr>
      <td>莫奈域FID</td>
      <td>131.68</td>
    </tr>
    <tr>
      <td>平均FID</td>
      <td>126.59</td>
    </tr>
  </table>
</div>

#### 1.3 训练指标分析

- **学习率变化**
  - 初始学习率：0.0001
  - 前100个epoch保持恒定
  - 100-200 epoch 线性衰减
  - 200-280 epoch 调整为新的学习率策略
  - 判别器和生成器学习率分别调整

- **FID分数变化**
  - 训练集：在200轮时平均FID约46.41；到280轮时升至51.08
  - 测试集：照片域FID约121.49；莫奈域FID约131.68；平均126.59

- **损失函数变化**
  - 生成器损失整体下降到0.45左右
  - 判别器损失稳定在0.02-0.04区间
  - 循环一致性损失降到0.05-0.06
  - 身份损失约为0.05

#### 1.4 优化策略调整（200-280 epochs）

- **学习率优化**：
  - 生成器: 0.00008 → 余弦衰减 → 最低0.000002
  - 判别器: 0.00002 → 余弦衰减 → 最低0.0000005

- **损失权重调整**：
  - Cycle Loss: 20.0
  - Identity Loss: 10.0

- **训练稳定性优化**：
  - 标签平滑度：0.05
  - 梯度累积步数：2
  - 预热阶段：2个epoch

#### 1.5 优化效果对比
<div align="center">
  <div class="comparison-results">
    <img src="assets/280与200epoch生成莫奈图片.jpg" 
         alt="280与200epoch生成莫奈图片对比" 
         width="90%"
         style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>🎨 200 vs 280 Epochs：莫奈画作风格生成效果对比</i></p>
    <br>
    <img src="assets/280与200epoch生成照片对比-1.jpg" 
         alt="280与200epoch生成照片对比" 
         width="90%"
         style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>📸 200 vs 280 Epochs：真实照片风格生成效果对比</i></p>
  </div>
</div>

#### 1.6 结论

1. **最佳模型配置（200 epoch）**
   - 平均FID达到最优（约46.41）
   - 损失值和图像质量达到平衡

2. **过度优化影响**
   - FID分数在后期出现上升
   - 可能出现过拟合或模型震荡

3. **建议**
   - 采用200 epoch的模型作为最终模型
   - 避免过度优化，保持训练参数的平衡

### 2. CycleGAN源码运行（第125轮）结果对比

以下内容来自**CycleGAN官方/源码**在第125轮时的中期结果，数值与本项目的域定义相反，因此这里做了相应的"方向"调整，以保持与本项目的A/B一致（A：照片，B：莫奈画作）。

#### 2.1 训练过程可视化
<div align="center">
  <div class="source-code-visualization">
    <img src="assets/源码125epoch_1.jpg" alt="源码训练曲线1" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>📈 源码训练125轮：生成器损失和判别器损失变化曲线</i></p>
    <br>
    <img src="assets/源码125epoch_2.jpg" alt="源码训练曲线2" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>📊 源码训练125轮：循环一致性损失和身份损失变化曲线</i></p>
  </div>
</div>

#### 2.2 FID分析
<div align="center">
  <img src="assets/源码fid.jpg" alt="源码FID分数变化" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
  <p><i>📊 源码训练125轮：FID分数变化趋势</i></p>
</div>

**当前FID值（第125轮）**
- **A->B** （照片 -> 莫奈画作）：**132.02**
- **B->A** （莫奈画作 -> 照片）：**127.59**

**FID趋势**
- **A->B方向**：从初始约142降低至132.02，改善幅度较小
- **B->A方向**：从初始约170降低至127.59，改善幅度更明显
- **整体趋势**：FID值在持续下降，但下降速度已经放缓

#### 2.2 损失值分析（第693300步）

- **生成器损失**
  - G_A (照片->莫奈): 0.8700
  - G_B (莫奈->照片): 0.9152
  - 两个生成器损失值相近，训练较为平衡

- **循环一致性损失**
  - cycle_A (照片->莫奈->照片): **0.8396**
  - cycle_B (莫奈->照片->莫奈): **0.5270**
  - 两个cycle loss都维持在较低水平，但A方向稍高

- **判别器损失**
  - D_A: 0.0514 (对应照片->莫奈的判别器)
  - D_B: 0.2747 (对应莫奈->照片的判别器)
  - 判别器损失保持在合理范围，无模式崩溃

- **身份映射损失**
  - idt_A (照片域): 0.2105
  - idt_B (莫奈域): 0.2637
  - 身份损失较低，模型保持了较好的风格一致性

#### 2.3 训练进展评估

1. 所有损失值均呈稳定下降趋势
2. cycle loss 已经降至0.5~0.8区间，图像转换的可逆性较好
3. FID值的下降速度在减缓，可能进入瓶颈期

**需要关注的问题**
1. FID值下降速度放缓
2. A->B方向（照片->莫奈）的改善较慢
3. cycle_A损失仍明显高于cycle_B，说明两个方向转换的难度不同

#### 2.4 建议

1. **继续训练到150轮**，观察是否能突破当前瓶颈
2. **增加A->B方向的监督**，加大照片->莫奈的关注度
3. 重点关注生成图像的视觉质量，辅以定量指标监控
4. 建议每5轮保存一次FID评估结果，以便及时观测趋势

#### 2.5 预期

1. **如果继续训练到150轮**：
   - FID值可能会降低到110~120之间
   - cycle loss 可能会降至0.4以下
2. **训练可能需要更长时间**来提升性能与稳定性

### 3. 性能对比分析

#### 3.1 FID分数对比

| 实现方式 | 照片域FID | 莫奈域FID | 平均FID | 训练轮次 |
|---------|-----------|-----------|---------|----------|
| 本项目   | 121.49    | 131.68    | 126.59  | 200      |
| 源码实现 | 127.59    | 132.02    | 129.81  | 125      |

#### 3.2 损失函数对比

| 损失类型 | 本项目(200epoch) | 源码(125epoch) | 差异分析 |
|---------|-----------------|----------------|----------|
| 生成器损失 | 0.45 | 0.89 | 本项目生成器损失更低，可能表明生成效果更好 |
| 判别器损失 | 0.02-0.04 | 0.05-0.27 | 本项目判别器更稳定，波动范围更小 |
| 循环一致性损失 | 0.05-0.06 | 0.53-0.84 | 本项目循环一致性显著更好，说明转换更可靠 |
| 身份损失 | 0.05 | 0.21-0.26 | 本项目身份保持能力更强 |

#### 3.3 主要改进点分析

1. **训练稳定性**
   - 本项目：通过梯度累积和标签平滑获得更稳定的训练过程
   - 源码：训练波动较大，损失值普遍较高

2. **FID表现**
   - 本项目：在更多轮次(200epoch)后达到较好水平
   - 源码：125epoch时已接近稳定，但改善空间仍然存在

3. **损失控制**
   - 本项目：所有损失值都明显低于源码实现
   - 源码：损失值较高但仍在合理范围内

4. **优化策略**
   - 本项目：
     * 实现了动态学习率调整
     * 添加了梯度累积机制
     * 使用了标签平滑技术
   - 源码：
     * 使用固定学习率
     * 基础的优化器设置
     * 简单的训练流程

#### 3.4 综合评估

1. **优势**
   - 更低的损失值
   - 更稳定的训练过程
   - 更好的循环一致性
   - 更强的身份保持能力

2. **改进空间**
   - FID分数仍有提升空间
   - 训练时间较长
   - 计算资源需求较高

3. **建议**
   - 可以尝试结合两种实现的优点
   - 进一步优化训练效率
   - 探索更多的训练稳定性技巧

## 使用说明

1. 准备数据：
```bash
# 将数据放在data目录下
data/
  ├── trainA/  # 照片训练集
  ├── trainB/  # 莫奈画作训练集
  ├── testA/   # 照片测试集
  └── testB/   # 莫奈画作测试集
```

2. 训练模型：
```bash
python train.py
```

3. 重新计算FID（如需要）：
```bash
python recalculate_fid.py
```

## 注意事项

1. GPU内存使用：
   - FID计算时使用较小的batch size（2）
   - 定期清理GPU缓存
   - 使用混合精度训练降低内存占用

2. 训练稳定性：
   - 监控损失值的突变
   - 关注生成器和判别器的平衡
   - 适时调整学习率

3. 实验监控：
   - 使用Wandb跟踪训练过程
   - 定期检查生成图像质量
   - 监控FID分数变化趋势

## 未来改进

1. 模型架构：
   - 探索注意力机制
   - 尝试不同的归一化方法
   - 优化网络深度和宽度

2. 训练策略：
   - 实现动态学习率调整
   - 研究新的损失函数组合
   - 增加数据增强方法

3. 评估体系：
   - 引入人类评估机制
   - 添加其他定量指标（如SSIM、LPIPS等）
   - 开发自动化测试流程

## 致谢

本项目基于CycleGAN论文实现：
[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)

## License

MIT License 