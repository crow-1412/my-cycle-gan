# Monet Style Transfer CycleGAN | è«å¥ˆé£æ ¼è½¬æ¢ CycleGAN

[English](#english) | [ä¸­æ–‡](#chinese)

<a name="english"></a>
# Monet Style Transfer CycleGAN

A CycleGAN-based project for bidirectional style transfer between photographs and Monet paintings:
- Convert real photos to Monet painting style
- Convert Monet painting style to realistic photo style

## Features

- Bidirectional style transfer
- Improved FID evaluation method
- Optimized training strategy
- Experiment tracking with Wandb
- Mixed precision training
- Automatic learning rate adjustment

## Requirements

```bash
torch>=1.7.0
torchvision>=0.8.0
wandb
numpy
pillow
tqdm
scipy
pytorch-fid
```

## Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ trainA/    # Training set photos
â”‚   â”œâ”€â”€ trainB/    # Training set Monet paintings
â”‚   â”œâ”€â”€ testA/     # Test set photos
â”‚   â””â”€â”€ testB/     # Test set Monet paintings
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ generator.py       # Generator model
â”‚   â””â”€â”€ discriminator.py   # Discriminator model
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataset.py        # Dataset loading
â”‚   â””â”€â”€ fid_score.py      # FID score calculation
â”œâ”€â”€ train.py              # Training script
â”œâ”€â”€ recalculate_fid.py    # FID recalculation script
â””â”€â”€ README.md
```

## Technical Details

### Model Architecture

#### Generator
- Based on ResNet architecture
- 9 residual blocks for feature extraction and transformation
- Instance normalization to preserve style information
- Reflection padding for edge consistency
- Tanh activation for output range [-1,1]

#### Discriminator
- PatchGAN structure focusing on local features
- Instance normalization
- LeakyReLU activation (slope 0.2)
- 70x70 receptive field

### Loss Functions

1. GAN Loss
   - Using MSE loss
   - Label smoothing for real and fake labels
   - Enhances generation authenticity

2. Cycle Loss
   - L1 loss
   - Weight: 20.0
   - Ensures image transformation reversibility
   - Maintains content consistency

3. Identity Loss
   - L1 loss
   - Weight: 10.0
   - Helps preserve color and composition
   - Prevents unnecessary style transfer

### Evaluation Metrics

#### FID Score (FrÃ©chet Inception Distance)
- Uses pretrained Inception-v3 for feature extraction
- Measures feature distribution distance
- Evaluates both domains separately:
  - Photo domain FID: Test set photos (774) vs generated photos
  - Monet domain FID: Test set Monet paintings (131) vs generated paintings
- Calculated every 10 epochs
- Lower values indicate better quality
- Uses independent test set for objective evaluation

## Training Strategy

### Base Configuration
```python
config = {
    'epochs': 200,
    'batch_size': 8,
    'lr': 0.0001,
    'b1': 0.5,
    'b2': 0.999,
    'lambda_cycle': 15.0,
    'lambda_identity': 7.5,
    'gradient_accumulation_steps': 4
}
```

### Optimization Techniques
1. Learning Rate Schedule:
   - Warmup phase (5 epochs)
   - Constant learning rate phase
   - Linear decay (starting from epoch 100)

2. Training Stability:
   - Gradient accumulation (updates every 4 steps)
   - Mixed precision training (reduces memory usage)
   - Larger batch size (8) for stability

3. Checkpoint Saving:
   - Every 5 epochs
   - Saves complete training state
   - Supports training resumption

## Experimental Results

This section integrates results from both **our custom training** and **CycleGAN source code training (125 epochs)** for comparison.

### 1. Our Training Process and Results

#### 1.1 Training Curves
<div align="center">
  <div class="training-visualization">
    <img src="assets/200epoch_1.jpg" alt="Training Curves 1" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“ˆ First 200 epochs: Learning rate, FID scores, and generator loss curves</i></p>
    <br>
    <img src="assets/200epoch_2.jpg" alt="Training Curves 2" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“Š First 200 epochs: Discriminator loss, cycle consistency loss, and identity loss curves</i></p>
  </div>
</div>

#### 1.2 Test Set FID Evaluation
<div align="center">
  <img src="assets/test_fid_scores.png" alt="Test Set FID Scores" width="80%">
  <p><i>ğŸ“Š Test Set FID Score Trends</i></p>
  <br>
  <table>
    <tr>
      <th>Metric</th>
      <th>Value</th>
    </tr>
    <tr>
      <td>Photo Domain FID</td>
      <td>121.49</td>
    </tr>
    <tr>
      <td>Monet Domain FID</td>
      <td>131.68</td>
    </tr>
    <tr>
      <td>Average FID</td>
      <td>126.59</td>
    </tr>
  </table>
</div>

#### 1.3 Training Metrics Analysis

- **Learning Rate Changes**
  - Initial learning rate: 0.0001
  - Constant for first 100 epochs
  - Linear decay from 100-200 epochs
  - New strategy for 200-280 epochs
  - Separate adjustments for discriminator and generator

- **FID Score Changes**
  - Training set: ~46.41 at 200 epochs; increased to 51.08 at 280 epochs
  - Test set: Photo domain ~121.49; Monet domain ~131.68; Average 126.59

- **Loss Function Changes**
  - Generator loss decreased to ~0.45
  - Discriminator loss stabilized at 0.02-0.04
  - Cycle consistency loss reduced to 0.05-0.06
  - Identity loss around 0.05

#### 1.4 Optimization Strategy Adjustments (200-280 epochs)

- **Learning Rate Optimization**:
  - Generator: 0.00008 â†’ cosine decay â†’ minimum 0.000002
  - Discriminator: 0.00002 â†’ cosine decay â†’ minimum 0.0000005

- **Loss Weights**:
  - Cycle Loss: 20.0
  - Identity Loss: 10.0

- **Training Stability**:
  - Label smoothing: 0.05
  - Gradient accumulation steps: 2
  - Warmup phase: 2 epochs

#### 1.5 Optimization Effect Comparison
<div align="center">
  <div class="comparison-results">
    <img src="assets/280ä¸200epochç”Ÿæˆè«å¥ˆå›¾ç‰‡.jpg" 
         alt="280 vs 200 Epochs Monet Generation" 
         width="90%"
         style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ¨ 200 vs 280 Epochs: Monet Style Generation Comparison</i></p>
    <br>
    <img src="assets/280ä¸200epochç”Ÿæˆç…§ç‰‡å¯¹æ¯”-1.jpg" 
         alt="280 vs 200 Epochs Photo Generation" 
         width="90%"
         style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“¸ 200 vs 280 Epochs: Real Photo Style Generation Comparison</i></p>
  </div>
</div>

#### 1.6 Conclusions

1. **Best Model Configuration (200 epochs)**
   - Optimal average FID (~46.41)
   - Balanced loss values and image quality

2. **Over-optimization Effects**
   - FID scores increased in later stages
   - Possible overfitting or model oscillation

3. **Recommendations**
   - Use 200-epoch model as final model
   - Avoid over-optimization
   - Maintain balanced training parameters

### 2. CycleGAN Source Code Results (125 epochs)

Results from the **official CycleGAN source code** at 125 epochs, with domain definitions adjusted to match our project (A: photos, B: Monet paintings).

#### 2.1 Training Process Visualization
<div align="center">
  <div class="source-code-visualization">
    <img src="assets/æºç 125epoch_1.jpg" alt="Source Code Training Curves 1" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“ˆ Source Code 125 epochs: Generator and discriminator loss curves</i></p>
    <br>
    <img src="assets/æºç 125epoch_2.jpg" alt="Source Code Training Curves 2" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“Š Source Code 125 epochs: Cycle consistency and identity loss curves</i></p>
  </div>
</div>

#### 2.2 FID Analysis
<div align="center">
  <img src="assets/æºç fid.jpg" alt="Source Code FID Scores" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
  <p><i>ğŸ“Š Source Code 125 epochs: FID score trends</i></p>
</div>

**Current FID Values (125 epochs)**
- **A->B** (Photo -> Monet): **132.02**
- **B->A** (Monet -> Photo): **127.59**

**FID Trends**
- **A->B direction**: Decreased from ~142 to 132.02, smaller improvement
- **B->A direction**: Decreased from ~170 to 127.59, more significant improvement
- **Overall trend**: FID values decreasing but at a slower rate

#### 2.3 Loss Value Analysis (Step 693300)

- **Generator Loss**
  - G_A (Photo->Monet): 0.8700
  - G_B (Monet->Photo): 0.9152
  - Both generator losses similar, indicating balanced training

- **Cycle Consistency Loss**
  - cycle_A (Photo->Monet->Photo): **0.8396**
  - cycle_B (Monet->Photo->Monet): **0.5270**
  - Both cycle losses at low levels, A direction slightly higher

- **Discriminator Loss**
  - D_A: 0.0514 (Photo->Monet discriminator)
  - D_B: 0.2747 (Monet->Photo discriminator)
  - Discriminator losses within reasonable range, no mode collapse

- **Identity Mapping Loss**
  - idt_A (Photo domain): 0.2105
  - idt_B (Monet domain): 0.2637
  - Low identity losses indicate good style consistency

#### 2.4 Training Progress Assessment

1. All loss values show stable decrease
2. Cycle loss reduced to 0.5~0.8 range, good reversibility
3. FID value decrease rate slowing, possible bottleneck

**Areas of Concern**
1. Slowing FID improvement
2. Slower improvement in A->B direction
3. Higher cycle_A loss indicates different difficulty levels

#### 2.5 Recommendations

1. **Continue to 150 epochs** to potentially break through bottleneck
2. **Increase A->B supervision**
3. Focus on visual quality with quantitative monitoring
4. Save FID evaluations every 5 epochs

### 3. Performance Comparison Analysis

#### 3.1 FID Score Comparison

| Implementation | Photo FID | Monet FID | Average FID | Epochs |
|---------------|-----------|------------|-------------|---------|
| Our Project   | 121.49    | 131.68    | 126.59      | 200    |
| Source Code   | 127.59    | 132.02    | 129.81      | 125    |

#### 3.2 Loss Function Comparison

| Loss Type | Our Project (200 epoch) | Source Code (125 epoch) | Analysis |
|-----------|------------------------|-------------------------|-----------|
| Generator Loss | 0.45 | 0.89 | Our project shows lower generator loss, potentially better generation |
| Discriminator Loss | 0.02-0.04 | 0.05-0.27 | Our project has more stable discriminator, smaller fluctuation |
| Cycle Consistency Loss | 0.05-0.06 | 0.53-0.84 | Our project shows significantly better cycle consistency |
| Identity Loss | 0.05 | 0.21-0.26 | Our project maintains better identity preservation |

#### 3.3 Key Improvements Analysis

1. **Training Stability**
   - Our project: Better stability through gradient accumulation and label smoothing
   - Source code: Larger fluctuations, generally higher loss values

2. **FID Performance**
   - Our project: Better results after more epochs (200)
   - Source code: Stabilizing at 125 epochs but room for improvement

3. **Loss Control**
   - Our project: Significantly lower loss values across all metrics
   - Source code: Higher but reasonable loss values

4. **Optimization Strategy**
   - Our project:
     * Dynamic learning rate adjustment
     * Gradient accumulation mechanism
     * Label smoothing technique
   - Source code:
     * Fixed learning rate
     * Basic optimizer settings
     * Simple training process

#### 3.4 Overall Assessment

1. **Advantages**
   - Lower loss values
   - More stable training process
   - Better cycle consistency
   - Stronger identity preservation

2. **Areas for Improvement**
   - FID scores can be further improved
   - Longer training time
   - Higher computational resource requirements

3. **Suggestions**
   - Combine advantages of both implementations
   - Further optimize training efficiency
   - Explore more training stability techniques

## Usage Instructions

1. Prepare data:
```bash
# Place data in the data directory
data/
  â”œâ”€â”€ trainA/  # Training set photos
  â”œâ”€â”€ trainB/  # Training set Monet paintings
  â”œâ”€â”€ testA/   # Test set photos
  â””â”€â”€ testB/   # Test set Monet paintings
```

2. Train model:
```bash
python train.py
```

3. Recalculate FID (if needed):
```bash
python recalculate_fid.py
```

## Notes

1. GPU Memory Usage:
   - Small batch size (2) for FID calculation
   - Regular GPU cache clearing
   - Mixed precision training for memory efficiency

2. Training Stability:
   - Monitor loss value spikes
   - Watch generator-discriminator balance
   - Adjust learning rate as needed

3. Experiment Monitoring:
   - Track training process with Wandb
   - Regular image quality checks
   - Monitor FID score trends

## Future Improvements

1. Model Architecture:
   - Explore attention mechanisms
   - Try different normalization methods
   - Optimize network depth and width

2. Training Strategy:
   - Implement dynamic learning rate adjustment
   - Research new loss function combinations
   - Add data augmentation methods

3. Evaluation System:
   - Introduce human evaluation mechanism
   - Add more quantitative metrics (SSIM, LPIPS, etc.)
   - Develop automated testing process

## Acknowledgments

This project is based on the CycleGAN paper:
[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)

## License

MIT License

---

<a name="chinese"></a>
# è«å¥ˆé£æ ¼è½¬æ¢ CycleGAN

åŸºäºCycleGANçš„ç…§ç‰‡ä¸è«å¥ˆç”»ä½œé£æ ¼è½¬æ¢é¡¹ç›®ã€‚è¯¥é¡¹ç›®å®ç°äº†åŒå‘é£æ ¼è½¬æ¢ï¼š
- å°†çœŸå®ç…§ç‰‡è½¬æ¢ä¸ºè«å¥ˆç”»ä½œé£æ ¼
- å°†è«å¥ˆç”»ä½œé£æ ¼è½¬æ¢ä¸ºçœŸå®ç…§ç‰‡é£æ ¼

## é¡¹ç›®ç‰¹ç‚¹

- åŒå‘é£æ ¼è½¬æ¢
- æ”¹è¿›çš„FIDè¯„ä¼°æ–¹æ³•
- ä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥
- ä½¿ç”¨Wandbè¿›è¡Œå®éªŒè·Ÿè¸ª
- æ··åˆç²¾åº¦è®­ç»ƒ
- è‡ªåŠ¨å­¦ä¹ ç‡è°ƒæ•´

## ç¯å¢ƒè¦æ±‚

```bash
torch>=1.7.0
torchvision>=0.8.0
wandb
numpy
pillow
tqdm
scipy
pytorch-fid
```

## é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ trainA/    # è®­ç»ƒé›†ç…§ç‰‡
â”‚   â”œâ”€â”€ trainB/    # è®­ç»ƒé›†è«å¥ˆç”»ä½œ
â”‚   â”œâ”€â”€ testA/     # æµ‹è¯•é›†ç…§ç‰‡
â”‚   â””â”€â”€ testB/     # æµ‹è¯•é›†è«å¥ˆç”»ä½œ
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ generator.py       # ç”Ÿæˆå™¨æ¨¡å‹
â”‚   â””â”€â”€ discriminator.py   # åˆ¤åˆ«å™¨æ¨¡å‹
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataset.py        # æ•°æ®é›†åŠ è½½
â”‚   â””â”€â”€ fid_score.py      # FIDåˆ†æ•°è®¡ç®—
â”œâ”€â”€ train.py              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ recalculate_fid.py    # FIDé‡æ–°è®¡ç®—è„šæœ¬
â””â”€â”€ README.md
```

## æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹æ¶æ„

#### ç”Ÿæˆå™¨ (Generator)
- åŸºäºResNetæ¶æ„
- 9ä¸ªæ®‹å·®å—ç”¨äºç‰¹å¾æå–å’Œè½¬æ¢
- ä½¿ç”¨å®ä¾‹å½’ä¸€åŒ–é¿å…é£æ ¼ä¿¡æ¯æŸå¤±
- åå°„å¡«å……ä¿æŒè¾¹ç¼˜ä¸€è‡´æ€§
- Tanhæ¿€æ´»å‡½æ•°ç¡®ä¿è¾“å‡ºèŒƒå›´åœ¨[-1,1]

#### åˆ¤åˆ«å™¨ (Discriminator)
- PatchGANç»“æ„ï¼Œå…³æ³¨å±€éƒ¨ç‰¹å¾
- å®ä¾‹å½’ä¸€åŒ–
- LeakyReLUæ¿€æ´»å‡½æ•°ï¼ˆæ–œç‡0.2ï¼‰
- 70x70æ„Ÿå—é‡

### æŸå¤±å‡½æ•°

1. GAN Loss
   - ä½¿ç”¨MSEæŸå¤±
   - å¸¦æ ‡ç­¾å¹³æ»‘çš„çœŸå®æ ‡ç­¾å’Œè™šå‡æ ‡ç­¾
   - ç”¨äºæå‡ç”Ÿæˆå›¾åƒçš„çœŸå®æ€§

2. Cycle Loss (å¾ªç¯ä¸€è‡´æ€§æŸå¤±)
   - L1æŸå¤±
   - æƒé‡ï¼š20.0
   - ç¡®ä¿å›¾åƒè½¬æ¢çš„å¯é€†æ€§
   - ä¿æŒå†…å®¹çš„ä¸€è‡´æ€§

3. Identity Loss (èº«ä»½æŸå¤±)
   - L1æŸå¤±
   - æƒé‡ï¼š10.0
   - å¸®åŠ©ä¿æŒé¢œè‰²å’Œæ•´ä½“æ„å›¾
   - é˜²æ­¢ä¸å¿…è¦çš„é£æ ¼è½¬æ¢

### è¯„ä¼°æŒ‡æ ‡

#### FIDåˆ†æ•° (FrÃ©chet Inception Distance)
- ä½¿ç”¨é¢„è®­ç»ƒçš„Inception-v3æ¨¡å‹æå–ç‰¹å¾
- è®¡ç®—çœŸå®å›¾åƒå’Œç”Ÿæˆå›¾åƒç‰¹å¾åˆ†å¸ƒçš„è·ç¦»
- åˆ†åˆ«è¯„ä¼°ä¸¤ä¸ªåŸŸçš„è½¬æ¢è´¨é‡ï¼š
  - ç…§ç‰‡åŸŸFIDï¼šæµ‹è¯•é›†çœŸå®ç…§ç‰‡(774å¼ )vsç”Ÿæˆç…§ç‰‡
  - è«å¥ˆåŸŸFIDï¼šæµ‹è¯•é›†è«å¥ˆç”»ä½œ(131å¼ )vsç”Ÿæˆè«å¥ˆç”»ä½œ
- æ¯10ä¸ªepochè®¡ç®—ä¸€æ¬¡
- å€¼è¶Šä½è¡¨ç¤ºç”Ÿæˆè´¨é‡è¶Šå¥½
- ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•é›†è¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°çš„å®¢è§‚æ€§

## è®­ç»ƒç­–ç•¥

### åŸºç¡€é…ç½®
```python
config = {
    'epochs': 200,
    'batch_size': 8,
    'lr': 0.0001,
    'b1': 0.5,
    'b2': 0.999,
    'lambda_cycle': 15.0,
    'lambda_identity': 7.5,
    'gradient_accumulation_steps': 4
}
```

### ä¼˜åŒ–æŠ€å·§
1. å­¦ä¹ ç‡è°ƒåº¦ï¼š
   - é¢„çƒ­é˜¶æ®µï¼ˆ5ä¸ªepochï¼‰
   - æ’å®šå­¦ä¹ ç‡é˜¶æ®µ
   - çº¿æ€§è¡°å‡ï¼ˆä»100epochå¼€å§‹ï¼‰

2. è®­ç»ƒç¨³å®šæ€§ï¼š
   - æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¯4æ­¥æ›´æ–°ä¸€æ¬¡ï¼‰
   - æ··åˆç²¾åº¦è®­ç»ƒï¼ˆé™ä½æ˜¾å­˜ä½¿ç”¨ï¼‰
   - è¾ƒå¤§çš„batch sizeï¼ˆ8ï¼‰æé«˜ç¨³å®šæ€§

3. æ£€æŸ¥ç‚¹ä¿å­˜ï¼š
   - æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡
   - ä¿å­˜å®Œæ•´çš„è®­ç»ƒçŠ¶æ€
   - æ”¯æŒæ–­ç‚¹ç»­è®­

## å®éªŒè¿‡ç¨‹ä¸ç»“æœ

æœ¬èŠ‚æ•´åˆäº†**æœ¬é¡¹ç›®è‡ªå®šä¹‰è®­ç»ƒ**ä¸**CycleGANæºç è®­ç»ƒ(125è½®)**çš„ç»“æœï¼Œç”¨äºå¯¹æ¯”å’Œåˆ†æã€‚

### 1. æœ¬é¡¹ç›®çš„è®­ç»ƒè¿‡ç¨‹ä¸ç»“æœ

#### 1.1 è®­ç»ƒæ›²çº¿å±•ç¤º
<div align="center">
  <div class="training-visualization">
    <img src="assets/200epoch_1.jpg" alt="è®­ç»ƒæ›²çº¿å›¾1" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“ˆ å‰ 200epoch å­¦ä¹ ç‡ã€FIDåˆ†æ•°å’Œç”Ÿæˆå™¨æŸå¤±å˜åŒ–æ›²çº¿</i></p>
    <br>
    <img src="assets/200epoch_2.jpg" alt="è®­ç»ƒæ›²çº¿å›¾2" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“Š å‰ 200epoch åˆ¤åˆ«å™¨æŸå¤±ã€å¾ªç¯ä¸€è‡´æ€§æŸå¤±å’Œèº«ä»½æŸå¤±å˜åŒ–æ›²çº¿</i></p>
  </div>
</div>

#### 1.2 æµ‹è¯•é›†FIDè¯„ä¼°ç»“æœ
<div align="center">
  <img src="assets/test_fid_scores.png" alt="æµ‹è¯•é›†FIDåˆ†æ•°å˜åŒ–" width="80%">
  <p><i>ğŸ“Š æµ‹è¯•é›†FIDåˆ†æ•°å˜åŒ–è¶‹åŠ¿</i></p>
  <br>
  <table>
    <tr>
      <th>æŒ‡æ ‡</th>
      <th>æ•°å€¼</th>
    </tr>
    <tr>
      <td>ç…§ç‰‡åŸŸFID</td>
      <td>121.49</td>
    </tr>
    <tr>
      <td>è«å¥ˆåŸŸFID</td>
      <td>131.68</td>
    </tr>
    <tr>
      <td>å¹³å‡FID</td>
      <td>126.59</td>
    </tr>
  </table>
</div>

#### 1.3 è®­ç»ƒæŒ‡æ ‡åˆ†æ

- **å­¦ä¹ ç‡å˜åŒ–**
  - åˆå§‹å­¦ä¹ ç‡ï¼š0.0001
  - å‰100ä¸ªepochä¿æŒæ’å®š
  - 100-200 epoch çº¿æ€§è¡°å‡
  - 200-280 epoch è°ƒæ•´ä¸ºæ–°çš„å­¦ä¹ ç‡ç­–ç•¥
  - åˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨å­¦ä¹ ç‡åˆ†åˆ«è°ƒæ•´

- **FIDåˆ†æ•°å˜åŒ–**
  - è®­ç»ƒé›†ï¼šåœ¨200è½®æ—¶å¹³å‡FIDçº¦46.41ï¼›åˆ°280è½®æ—¶å‡è‡³51.08
  - æµ‹è¯•é›†ï¼šç…§ç‰‡åŸŸFIDçº¦121.49ï¼›è«å¥ˆåŸŸFIDçº¦131.68ï¼›å¹³å‡126.59

- **æŸå¤±å‡½æ•°å˜åŒ–**
  - ç”Ÿæˆå™¨æŸå¤±æ•´ä½“ä¸‹é™åˆ°0.45å·¦å³
  - åˆ¤åˆ«å™¨æŸå¤±ç¨³å®šåœ¨0.02-0.04åŒºé—´
  - å¾ªç¯ä¸€è‡´æ€§æŸå¤±é™åˆ°0.05-0.06
  - èº«ä»½æŸå¤±çº¦ä¸º0.05

#### 1.4 ä¼˜åŒ–ç­–ç•¥è°ƒæ•´ï¼ˆ200-280 epochsï¼‰

- **å­¦ä¹ ç‡ä¼˜åŒ–**ï¼š
  - ç”Ÿæˆå™¨: 0.00008 â†’ ä½™å¼¦è¡°å‡ â†’ æœ€ä½0.000002
  - åˆ¤åˆ«å™¨: 0.00002 â†’ ä½™å¼¦è¡°å‡ â†’ æœ€ä½0.0000005

- **æŸå¤±æƒé‡è°ƒæ•´**ï¼š
  - Cycle Loss: 20.0
  - Identity Loss: 10.0

- **è®­ç»ƒç¨³å®šæ€§ä¼˜åŒ–**ï¼š
  - æ ‡ç­¾å¹³æ»‘åº¦ï¼š0.05
  - æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼š2
  - é¢„çƒ­é˜¶æ®µï¼š2ä¸ªepoch

#### 1.5 ä¼˜åŒ–æ•ˆæœå¯¹æ¯”
<div align="center">
  <div class="comparison-results">
    <img src="assets/280ä¸200epochç”Ÿæˆè«å¥ˆå›¾ç‰‡.jpg" 
         alt="280ä¸200epochç”Ÿæˆè«å¥ˆå›¾ç‰‡å¯¹æ¯”" 
         width="90%"
         style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ¨ 200 vs 280 Epochsï¼šè«å¥ˆç”»ä½œé£æ ¼ç”Ÿæˆæ•ˆæœå¯¹æ¯”</i></p>
    <br>
    <img src="assets/280ä¸200epochç”Ÿæˆç…§ç‰‡å¯¹æ¯”-1.jpg" 
         alt="280ä¸200epochç”Ÿæˆç…§ç‰‡å¯¹æ¯”" 
         width="90%"
         style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“¸ 200 vs 280 Epochsï¼šçœŸå®ç…§ç‰‡é£æ ¼ç”Ÿæˆæ•ˆæœå¯¹æ¯”</i></p>
  </div>
</div>

#### 1.6 ç»“è®º

1. **æœ€ä½³æ¨¡å‹é…ç½®ï¼ˆ200 epochï¼‰**
   - å¹³å‡FIDè¾¾åˆ°æœ€ä¼˜ï¼ˆçº¦46.41ï¼‰
   - æŸå¤±å€¼å’Œå›¾åƒè´¨é‡è¾¾åˆ°å¹³è¡¡

2. **è¿‡åº¦ä¼˜åŒ–å½±å“**
   - FIDåˆ†æ•°åœ¨åæœŸå‡ºç°ä¸Šå‡
   - å¯èƒ½å‡ºç°è¿‡æ‹Ÿåˆæˆ–æ¨¡å‹éœ‡è¡

3. **å»ºè®®**
   - é‡‡ç”¨200 epochçš„æ¨¡å‹ä½œä¸ºæœ€ç»ˆæ¨¡å‹
   - é¿å…è¿‡åº¦ä¼˜åŒ–ï¼Œä¿æŒè®­ç»ƒå‚æ•°çš„å¹³è¡¡

### 2. CycleGANæºç è¿è¡Œï¼ˆç¬¬125è½®ï¼‰ç»“æœå¯¹æ¯”

ä»¥ä¸‹å†…å®¹æ¥è‡ª**CycleGANå®˜æ–¹/æºç **åœ¨ç¬¬125è½®æ—¶çš„ä¸­æœŸç»“æœï¼Œæ•°å€¼ä¸æœ¬é¡¹ç›®çš„åŸŸå®šä¹‰ç›¸åï¼Œå› æ­¤è¿™é‡Œåšäº†ç›¸åº”çš„"æ–¹å‘"è°ƒæ•´ï¼Œä»¥ä¿æŒä¸æœ¬é¡¹ç›®çš„A/Bä¸€è‡´ï¼ˆAï¼šç…§ç‰‡ï¼ŒBï¼šè«å¥ˆç”»ä½œï¼‰ã€‚

#### 2.1 è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
<div align="center">
  <div class="source-code-visualization">
    <img src="assets/æºç 125epoch_1.jpg" alt="æºç è®­ç»ƒæ›²çº¿1" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“ˆ æºç è®­ç»ƒ125è½®ï¼šç”Ÿæˆå™¨æŸå¤±å’Œåˆ¤åˆ«å™¨æŸå¤±å˜åŒ–æ›²çº¿</i></p>
    <br>
    <img src="assets/æºç 125epoch_2.jpg" alt="æºç è®­ç»ƒæ›²çº¿2" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    <p><i>ğŸ“Š æºç è®­ç»ƒ125è½®ï¼šå¾ªç¯ä¸€è‡´æ€§æŸå¤±å’Œèº«ä»½æŸå¤±å˜åŒ–æ›²çº¿</i></p>
  </div>
</div>

#### 2.2 FIDåˆ†æ
<div align="center">
  <img src="assets/æºç fid.jpg" alt="æºç FIDåˆ†æ•°å˜åŒ–" width="80%" style="border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
  <p><i>ğŸ“Š æºç è®­ç»ƒ125è½®ï¼šFIDåˆ†æ•°å˜åŒ–è¶‹åŠ¿</i></p>
</div>

**å½“å‰FIDå€¼ï¼ˆç¬¬125è½®ï¼‰**
- **A->B** ï¼ˆç…§ç‰‡ -> è«å¥ˆç”»ä½œï¼‰ï¼š**132.02**
- **B->A** ï¼ˆè«å¥ˆç”»ä½œ -> ç…§ç‰‡ï¼‰ï¼š**127.59**

**FIDè¶‹åŠ¿**
- **A->Bæ–¹å‘**ï¼šä»åˆå§‹çº¦142é™ä½è‡³132.02ï¼Œæ”¹å–„å¹…åº¦è¾ƒå°
- **B->Aæ–¹å‘**ï¼šä»åˆå§‹çº¦170é™ä½è‡³127.59ï¼Œæ”¹å–„å¹…åº¦æ›´æ˜æ˜¾
- **æ•´ä½“è¶‹åŠ¿**ï¼šFIDå€¼åœ¨æŒç»­ä¸‹é™ï¼Œä½†ä¸‹é™é€Ÿåº¦å·²ç»æ”¾ç¼“

#### 2.3 æŸå¤±å€¼åˆ†æï¼ˆç¬¬693300æ­¥ï¼‰

- **ç”Ÿæˆå™¨æŸå¤±**
  - G_A (ç…§ç‰‡->è«å¥ˆ): 0.8700
  - G_B (è«å¥ˆ->ç…§ç‰‡): 0.9152
  - ä¸¤ä¸ªç”Ÿæˆå™¨æŸå¤±å€¼ç›¸è¿‘ï¼Œè®­ç»ƒè¾ƒä¸ºå¹³è¡¡

- **å¾ªç¯ä¸€è‡´æ€§æŸå¤±**
  - cycle_A (ç…§ç‰‡->è«å¥ˆ->ç…§ç‰‡): **0.8396**
  - cycle_B (è«å¥ˆ->ç…§ç‰‡->è«å¥ˆ): **0.5270**
  - ä¸¤ä¸ªcycle losséƒ½ç»´æŒåœ¨è¾ƒä½æ°´å¹³ï¼Œä½†Aæ–¹å‘ç¨é«˜

- **åˆ¤åˆ«å™¨æŸå¤±**
  - D_A: 0.0514 (å¯¹åº”ç…§ç‰‡->è«å¥ˆçš„åˆ¤åˆ«å™¨)
  - D_B: 0.2747 (å¯¹åº”è«å¥ˆ->ç…§ç‰‡çš„åˆ¤åˆ«å™¨)
  - åˆ¤åˆ«å™¨æŸå¤±ä¿æŒåœ¨åˆç†èŒƒå›´ï¼Œæ— æ¨¡å¼å´©æºƒ

- **èº«ä»½æ˜ å°„æŸå¤±**
  - idt_A (ç…§ç‰‡åŸŸ): 0.2105
  - idt_B (è«å¥ˆåŸŸ): 0.2637
  - èº«ä»½æŸå¤±è¾ƒä½ï¼Œæ¨¡å‹ä¿æŒäº†è¾ƒå¥½çš„é£æ ¼ä¸€è‡´æ€§

#### 2.4 è®­ç»ƒè¿›å±•è¯„ä¼°

1. æ‰€æœ‰æŸå¤±å€¼å‡å‘ˆç¨³å®šä¸‹é™è¶‹åŠ¿
2. cycle loss å·²ç»é™è‡³0.5~0.8åŒºé—´ï¼Œå›¾åƒè½¬æ¢çš„å¯é€†æ€§è¾ƒå¥½
3. FIDå€¼çš„ä¸‹é™é€Ÿåº¦åœ¨å‡ç¼“ï¼Œå¯èƒ½è¿›å…¥ç“¶é¢ˆæœŸ

**éœ€è¦å…³æ³¨çš„é—®é¢˜**
1. FIDå€¼ä¸‹é™é€Ÿåº¦æ”¾ç¼“
2. A->Bæ–¹å‘ï¼ˆç…§ç‰‡->è«å¥ˆï¼‰çš„æ”¹å–„è¾ƒæ…¢
3. cycle_AæŸå¤±ä»æ˜æ˜¾é«˜äºcycle_Bï¼Œè¯´æ˜ä¸¤ä¸ªæ–¹å‘è½¬æ¢çš„éš¾åº¦ä¸åŒ

#### 2.5 å»ºè®®

1. **ç»§ç»­è®­ç»ƒåˆ°150è½®**ï¼Œè§‚å¯Ÿæ˜¯å¦èƒ½çªç ´å½“å‰ç“¶é¢ˆ
2. **å¢åŠ A->Bæ–¹å‘çš„ç›‘ç£**ï¼ŒåŠ å¤§ç…§ç‰‡->è«å¥ˆçš„å…³æ³¨åº¦
3. é‡ç‚¹å…³æ³¨ç”Ÿæˆå›¾åƒçš„è§†è§‰è´¨é‡ï¼Œè¾…ä»¥å®šé‡æŒ‡æ ‡ç›‘æ§
4. å»ºè®®æ¯5è½®ä¿å­˜ä¸€æ¬¡FIDè¯„ä¼°ç»“æœï¼Œä»¥ä¾¿åŠæ—¶è§‚æµ‹è¶‹åŠ¿

### 3. æ€§èƒ½å¯¹æ¯”åˆ†æ

#### 3.1 FIDåˆ†æ•°å¯¹æ¯”

| å®ç°æ–¹å¼ | ç…§ç‰‡åŸŸFID | è«å¥ˆåŸŸFID | å¹³å‡FID | è®­ç»ƒè½®æ¬¡ |
|---------|-----------|-----------|---------|----------|
| æœ¬é¡¹ç›®   | 121.49    | 131.68    | 126.59  | 200      |
| æºç å®ç° | 127.59    | 132.02    | 129.81  | 125      |

#### 3.2 æŸå¤±å‡½æ•°å¯¹æ¯”

| æŸå¤±ç±»å‹ | æœ¬é¡¹ç›®(200epoch) | æºç (125epoch) | å·®å¼‚åˆ†æ |
|---------|-----------------|----------------|----------|
| ç”Ÿæˆå™¨æŸå¤± | 0.45 | 0.89 | æœ¬é¡¹ç›®ç”Ÿæˆå™¨æŸå¤±æ›´ä½ï¼Œå¯èƒ½è¡¨æ˜ç”Ÿæˆæ•ˆæœæ›´å¥½ |
| åˆ¤åˆ«å™¨æŸå¤± | 0.02-0.04 | 0.05-0.27 | æœ¬é¡¹ç›®åˆ¤åˆ«å™¨æ›´ç¨³å®šï¼Œæ³¢åŠ¨èŒƒå›´æ›´å° |
| å¾ªç¯ä¸€è‡´æ€§æŸå¤± | 0.05-0.06 | 0.53-0.84 | æœ¬é¡¹ç›®å¾ªç¯ä¸€è‡´æ€§æ˜¾è‘—æ›´å¥½ï¼Œè¯´æ˜è½¬æ¢æ›´å¯é  |
| èº«ä»½æŸå¤± | 0.05 | 0.21-0.26 | æœ¬é¡¹ç›®èº«ä»½ä¿æŒèƒ½åŠ›æ›´å¼º |

#### 3.3 ä¸»è¦æ”¹è¿›ç‚¹åˆ†æ

1. **è®­ç»ƒç¨³å®šæ€§**
   - æœ¬é¡¹ç›®ï¼šé€šè¿‡æ¢¯åº¦ç´¯ç§¯å’Œæ ‡ç­¾å¹³æ»‘è·å¾—æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹
   - æºç ï¼šè®­ç»ƒæ³¢åŠ¨è¾ƒå¤§ï¼ŒæŸå¤±å€¼æ™®éè¾ƒé«˜

2. **FIDè¡¨ç°**
   - æœ¬é¡¹ç›®ï¼šåœ¨æ›´å¤šè½®æ¬¡(200epoch)åè¾¾åˆ°è¾ƒå¥½æ°´å¹³
   - æºç ï¼š125epochæ—¶å·²æ¥è¿‘ç¨³å®šï¼Œä½†æ”¹å–„ç©ºé—´ä»ç„¶å­˜åœ¨

3. **æŸå¤±æ§åˆ¶**
   - æœ¬é¡¹ç›®ï¼šæ‰€æœ‰æŸå¤±å€¼éƒ½æ˜æ˜¾ä½äºæºç å®ç°
   - æºç ï¼šæŸå¤±å€¼è¾ƒé«˜ä½†ä»åœ¨åˆç†èŒƒå›´å†…

4. **ä¼˜åŒ–ç­–ç•¥**
   - æœ¬é¡¹ç›®ï¼š
     * å®ç°äº†åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´
     * æ·»åŠ äº†æ¢¯åº¦ç´¯ç§¯æœºåˆ¶
     * ä½¿ç”¨äº†æ ‡ç­¾å¹³æ»‘æŠ€æœ¯
   - æºç ï¼š
     * ä½¿ç”¨å›ºå®šå­¦ä¹ ç‡
     * åŸºç¡€çš„ä¼˜åŒ–å™¨è®¾ç½®
     * ç®€å•çš„è®­ç»ƒæµç¨‹

#### 3.4 ç»¼åˆè¯„ä¼°

1. **ä¼˜åŠ¿**
   - æ›´ä½çš„æŸå¤±å€¼
   - æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹
   - æ›´å¥½çš„å¾ªç¯ä¸€è‡´æ€§
   - æ›´å¼ºçš„èº«ä»½ä¿æŒèƒ½åŠ›

2. **æ”¹è¿›ç©ºé—´**
   - FIDåˆ†æ•°ä»æœ‰æå‡ç©ºé—´
   - è®­ç»ƒæ—¶é—´è¾ƒé•¿
   - è®¡ç®—èµ„æºéœ€æ±‚è¾ƒé«˜

3. **å»ºè®®**
   - å¯ä»¥å°è¯•ç»“åˆä¸¤ç§å®ç°çš„ä¼˜ç‚¹
   - è¿›ä¸€æ­¥ä¼˜åŒ–è®­ç»ƒæ•ˆç‡
   - æ¢ç´¢æ›´å¤šçš„è®­ç»ƒç¨³å®šæ€§æŠ€å·§

## ä½¿ç”¨è¯´æ˜

1. å‡†å¤‡æ•°æ®ï¼š
```bash
# å°†æ•°æ®æ”¾åœ¨dataç›®å½•ä¸‹
data/
  â”œâ”€â”€ trainA/  # ç…§ç‰‡è®­ç»ƒé›†
  â”œâ”€â”€ trainB/  # è«å¥ˆç”»ä½œè®­ç»ƒé›†
  â”œâ”€â”€ testA/   # ç…§ç‰‡æµ‹è¯•é›†
  â””â”€â”€ testB/   # è«å¥ˆç”»ä½œæµ‹è¯•é›†
```

2. è®­ç»ƒæ¨¡å‹ï¼š
```bash
python train.py
```

3. é‡æ–°è®¡ç®—FIDï¼ˆå¦‚éœ€è¦ï¼‰ï¼š
```bash
python recalculate_fid.py
```

## æ³¨æ„äº‹é¡¹

1. GPUå†…å­˜ä½¿ç”¨ï¼š
   - FIDè®¡ç®—æ—¶ä½¿ç”¨è¾ƒå°çš„batch sizeï¼ˆ2ï¼‰
   - å®šæœŸæ¸…ç†GPUç¼“å­˜
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒé™ä½å†…å­˜å ç”¨

2. è®­ç»ƒç¨³å®šæ€§ï¼š
   - ç›‘æ§æŸå¤±å€¼çš„çªå˜
   - å…³æ³¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¹³è¡¡
   - é€‚æ—¶è°ƒæ•´å­¦ä¹ ç‡

3. å®éªŒç›‘æ§ï¼š
   - ä½¿ç”¨Wandbè·Ÿè¸ªè®­ç»ƒè¿‡ç¨‹
   - å®šæœŸæ£€æŸ¥ç”Ÿæˆå›¾åƒè´¨é‡
   - ç›‘æ§FIDåˆ†æ•°å˜åŒ–è¶‹åŠ¿

## æœªæ¥æ”¹è¿›

1. æ¨¡å‹æ¶æ„ï¼š
   - æ¢ç´¢æ³¨æ„åŠ›æœºåˆ¶
   - å°è¯•ä¸åŒçš„å½’ä¸€åŒ–æ–¹æ³•
   - ä¼˜åŒ–ç½‘ç»œæ·±åº¦å’Œå®½åº¦

2. è®­ç»ƒç­–ç•¥ï¼š
   - å®ç°åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´
   - ç ”ç©¶æ–°çš„æŸå¤±å‡½æ•°ç»„åˆ
   - å¢åŠ æ•°æ®å¢å¼ºæ–¹æ³•

3. è¯„ä¼°ä½“ç³»ï¼š
   - å¼•å…¥äººç±»è¯„ä¼°æœºåˆ¶
   - æ·»åŠ å…¶ä»–å®šé‡æŒ‡æ ‡ï¼ˆå¦‚SSIMã€LPIPSç­‰ï¼‰
   - å¼€å‘è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹

## è‡´è°¢

æœ¬é¡¹ç›®åŸºäºCycleGANè®ºæ–‡å®ç°ï¼š
[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)

## License

MIT License 